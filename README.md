# Métodos Numéricos y Optimización
* Profesor: 
 - Erick Palacios Moreno
* Correo
 - erick89.itam@gmail.com
* [Material del curso](https://www.dropbox.com/sh/1s0dff6r1wadl4l/AAAsydFMYL-iNy5nX4V3kFCOa?dl=0)

## Objetivo:
Proporcionar	los	 fundamentos,	las	herramientas	y	conceptos	teóricos y	 prácticos	 para	 que	l@s	estudiantes	 desarrollen habilidades	en	álgebra	lineal	numérica,	cómputo	en	paralelo,	convexidad	y	optimización para	la comprensión	 y	 entendimiento	 del	 papel	 y	 la	 contínua	 investigación (conocimiento	 de	 frontera) del	 análisis y	 optimización	 numérica en	 big	
data,	gran	escala,	inteligencia	artificial	y	machine	learning

## Descripción:
Los	 modelos	 o	 problemas	 de	 machine	 learning	 involucran	problemas	de	análisis	y	optimización	numérica,	en	el	curso	usaremos	esta	relación	para	estudiar	métodos	en	esta	rama	de	las	matemáticas	aplicadas	que	se	han	desarrollado	y	adaptado	para	resolverlos.	La	implementación de	dichos	métodos	en	la	computadora	es	crítico	al	ir	a	la	práctica,	por	lo	
que	 se	 estudiarán	 aspectos	 de	 eficiencia	 en	 la	 implementación	 del	método,	tales	como,	el	número de	operaciones	en	punto	flotante,	acceso	y	transferencia	 de	 los	 datos	 en	 dos	 tipos	 de	 arquitectura	 computacional:	sistemas	 de	memoria	 compartida	 y	 sistemas	 de	memoria	 distribuida.	Se	utilizará	el	lenguaje	C	para	el	uso	de	recursos	en	estas	arquitecturas	y se	estudiarán	 las	 siguientes	 extensiones	 a	 este	 lenguaje:	 MPI,	 OpenMP,	Pthreads	y	CUDA.

## Pre Requisitos:
Cálculo,	Álgebra	lineal,	Probabilidad	y	Estadística,	conocimiento de	programación	por	ejemplo	en	Matlab,	R	o	Python

## Temario:
1. Cómputo	científico.
  * Sistema	de	punto	flotante.
2. Cómputo	en	paralelo.
  * Sistemas	de	memoria	distribuida y	sistemas	de	memoria	compartida.
  * Extensiones	al	lenguaje	C:	MPI,	Pthreads,	OpenMP,	CUDA.
3. Cómputo	matricial.
  * Sistemas	de	ecuaciones	lineales.
  * Métodos	directos	y	factorizaciones	matriciales.
  * Métodos	iterativos.
  * Álgebra	multilineal:	tensores
  * Aplicaciones	del	álgebra	lineal	numérica	a	machine	learning.
4. Ecuaciones	no	lineales.
  * Método	de	Newton.
5. Convexidad.
  * Teoría
6. Optimización	sin	restricciones.
7. Optimización convexa.
  * Programación	lineal.
  * Programación	cuadrática.
  * Mínimos	cuadrados.
8. Optimización	con	restricciones.
9. Optimización	y	machine	learning


## REFERENCIAS:
1. [R.	L.	Burden,	J.	D.	Faires,	Numerical	Analysis,	Brooks/Cole	Cengage	Learning,	2005.]()
2. [M.	T.	Heath,	Scientific	Computing.	An	Introductory	Survey,	McGraw-Hill,	2002.]()
3. [P.	Pacheco,	An	Introduction	to	Parallel	Programming,	Morgan	Kaufmann,	2011.]()
4. [D.	B.	Kirk,	W.	W.	Hwu,	Programming	Massively	Parallel	Processors:	A	Hands-on Approach,	Morgan	Kaufmann,	2010.]()
5. [B.	W.	Kernighan,	D.	M.	Ritchie,	The	C	Programming	Language,	Prentice	Hall	Software	Series,	1988.]()
6. [NVIDIA, CUDA	Programming	Guide.	NVIDIA	Corporation,	2007]()
7. [G.	H.	Golub,	C.	F.	Van	Loan, Matrix	Computations.	John	Hopkins	University	Press,	2013.]()
8. [L.	Eldén,	Matrix Methods	in	Data	Mining	and	Pattern	recognition.	SIAM,	2007.]()
9. [S.	P.	Boyd,	L.	Vandenberghe, Convex	Optimization.	Cambridge	University	Press,	2004.]()
10. [J.	Nocedal,	S.	J.	Wright,	Numerical	Optimization.	Springer,	2006.]()
11. [C.	M.	Bishop, Pattern	Recognition	and	Machine Learning.	Springer.	2008.]()
